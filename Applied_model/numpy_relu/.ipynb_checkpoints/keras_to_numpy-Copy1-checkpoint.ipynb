{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Monahans Cleakfork Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Write numpy LeakyReLu for use in ANN acceleration\n",
    "Tensorflor model.predict is too slow bc it uses tensors optimized for batch predictions\n",
    "\n",
    "How to use:\n",
    "    Set path as the directory containing all the models. Each model has a directory with its saved_model.pb file inside\n",
    "    Set the search criteria. Use 'Monahans' or something.\n",
    "\n",
    "'''\n",
    "\n",
    "import konverter\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of directories inside the path directory, then only retain the ones containing the keyword\n",
    "path = r'C:\\Users\\markz\\OneDrive\\Documents\\logs\\logs\\scalars'\n",
    "dirList = [i for i in os.listdir(path) if 'Monahans' in i]\n",
    "#print(dirList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: C:\\Users\\markz\\OneDrive\\Documents\\logs\\logs\\scalars\\C0_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201219-124815\\C0_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201219-124815.h5\n",
      "\u001b[92m\n",
      "Successfully got model architecture! ðŸ˜„\n",
      "\u001b[0m\u001b[37m\n",
      "\u001b[38;5;220mLayers:\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (4, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 1)\u001b[0m\u001b[37m\n",
      "\u001b[0m\u001b[37m\u001b[38;5;220m\n",
      "ðŸ”¨ Now building pure Python + NumPy model...\u001b[0m\u001b[37m\n",
      "\u001b[92mðŸ™Œ Saved Konverted model!\u001b[0m\u001b[37m\n",
      "\u001b[92mOutput model file: C:/Users/markz/OneDrive/Documents/logs/logs/scalars/C0_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201219-124815/C0_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201219-124815_Konverted.py\u001b[0m\u001b[37m\n",
      "\u001b[92mWeights and biases file: C:/Users/markz/OneDrive/Documents/logs/logs/scalars/C0_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201219-124815/C0_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201219-124815_Konverted_weights.npz\u001b[0m\u001b[37m\n",
      "\u001b[38;5;220m\n",
      "â— Make sure to change the path inside the wrapper file to your weights if you move the file elsewhere.\u001b[0m\u001b[37m\n",
      "Converted C0_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201219-124815\n",
      "Saved to: C:\\Users\\markz\\OneDrive\\Documents\\logs\\logs\\scalars\\C1_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-153022\\C1_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-153022.h5\n",
      "\u001b[92m\n",
      "Successfully got model architecture! ðŸ˜„\n",
      "\u001b[0m\u001b[37m\n",
      "\u001b[38;5;220mLayers:\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (4, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 1)\u001b[0m\u001b[37m\n",
      "\u001b[0m\u001b[37m\u001b[38;5;220m\n",
      "ðŸ”¨ Now building pure Python + NumPy model...\u001b[0m\u001b[37m\n",
      "\u001b[92mðŸ™Œ Saved Konverted model!\u001b[0m\u001b[37m\n",
      "\u001b[92mOutput model file: C:/Users/markz/OneDrive/Documents/logs/logs/scalars/C1_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-153022/C1_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-153022_Konverted.py\u001b[0m\u001b[37m\n",
      "\u001b[92mWeights and biases file: C:/Users/markz/OneDrive/Documents/logs/logs/scalars/C1_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-153022/C1_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-153022_Konverted_weights.npz\u001b[0m\u001b[37m\n",
      "\u001b[38;5;220m\n",
      "â— Make sure to change the path inside the wrapper file to your weights if you move the file elsewhere.\u001b[0m\u001b[37m\n",
      "Converted C1_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-153022\n",
      "Saved to: C:\\Users\\markz\\OneDrive\\Documents\\logs\\logs\\scalars\\C2_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-155553\\C2_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-155553.h5\n",
      "\u001b[92m\n",
      "Successfully got model architecture! ðŸ˜„\n",
      "\u001b[0m\u001b[37m\n",
      "\u001b[38;5;220mLayers:\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (4, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 1)\u001b[0m\u001b[37m\n",
      "\u001b[0m\u001b[37m\u001b[38;5;220m\n",
      "ðŸ”¨ Now building pure Python + NumPy model...\u001b[0m\u001b[37m\n",
      "\u001b[92mðŸ™Œ Saved Konverted model!\u001b[0m\u001b[37m\n",
      "\u001b[92mOutput model file: C:/Users/markz/OneDrive/Documents/logs/logs/scalars/C2_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-155553/C2_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-155553_Konverted.py\u001b[0m\u001b[37m\n",
      "\u001b[92mWeights and biases file: C:/Users/markz/OneDrive/Documents/logs/logs/scalars/C2_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-155553/C2_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-155553_Konverted_weights.npz\u001b[0m\u001b[37m\n",
      "\u001b[38;5;220m\n",
      "â— Make sure to change the path inside the wrapper file to your weights if you move the file elsewhere.\u001b[0m\u001b[37m\n",
      "Converted C2_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-155553\n",
      "Saved to: C:\\Users\\markz\\OneDrive\\Documents\\logs\\logs\\scalars\\C3_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-162525\\C3_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-162525.h5\n",
      "\u001b[92m\n",
      "Successfully got model architecture! ðŸ˜„\n",
      "\u001b[0m\u001b[37m\n",
      "\u001b[38;5;220mLayers:\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (4, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 1)\u001b[0m\u001b[37m\n",
      "\u001b[0m\u001b[37m\u001b[38;5;220m\n",
      "ðŸ”¨ Now building pure Python + NumPy model...\u001b[0m\u001b[37m\n",
      "\u001b[92mðŸ™Œ Saved Konverted model!\u001b[0m\u001b[37m\n",
      "\u001b[92mOutput model file: C:/Users/markz/OneDrive/Documents/logs/logs/scalars/C3_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-162525/C3_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-162525_Konverted.py\u001b[0m\u001b[37m\n",
      "\u001b[92mWeights and biases file: C:/Users/markz/OneDrive/Documents/logs/logs/scalars/C3_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-162525/C3_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-162525_Konverted_weights.npz\u001b[0m\u001b[37m\n",
      "\u001b[38;5;220m\n",
      "â— Make sure to change the path inside the wrapper file to your weights if you move the file elsewhere.\u001b[0m\u001b[37m\n",
      "Converted C3_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-162525\n",
      "Saved to: C:\\Users\\markz\\OneDrive\\Documents\\logs\\logs\\scalars\\C4_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-171255\\C4_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-171255.h5\n",
      "\u001b[92m\n",
      "Successfully got model architecture! ðŸ˜„\n",
      "\u001b[0m\u001b[37m\n",
      "\u001b[38;5;220mLayers:\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (4, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 1)\u001b[0m\u001b[37m\n",
      "\u001b[0m\u001b[37m\u001b[38;5;220m\n",
      "ðŸ”¨ Now building pure Python + NumPy model...\u001b[0m\u001b[37m\n",
      "\u001b[92mðŸ™Œ Saved Konverted model!\u001b[0m\u001b[37m\n",
      "\u001b[92mOutput model file: C:/Users/markz/OneDrive/Documents/logs/logs/scalars/C4_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-171255/C4_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-171255_Konverted.py\u001b[0m\u001b[37m\n",
      "\u001b[92mWeights and biases file: C:/Users/markz/OneDrive/Documents/logs/logs/scalars/C4_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-171255/C4_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-171255_Konverted_weights.npz\u001b[0m\u001b[37m\n",
      "\u001b[38;5;220m\n",
      "â— Make sure to change the path inside the wrapper file to your weights if you move the file elsewhere.\u001b[0m\u001b[37m\n",
      "Converted C4_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-171255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: C:\\Users\\markz\\OneDrive\\Documents\\logs\\logs\\scalars\\C5_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-173816\\C5_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-173816.h5\n",
      "\u001b[92m\n",
      "Successfully got model architecture! ðŸ˜„\n",
      "\u001b[0m\u001b[37m\n",
      "\u001b[38;5;220mLayers:\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (4, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 1)\u001b[0m\u001b[37m\n",
      "\u001b[0m\u001b[37m\u001b[38;5;220m\n",
      "ðŸ”¨ Now building pure Python + NumPy model...\u001b[0m\u001b[37m\n",
      "\u001b[92mðŸ™Œ Saved Konverted model!\u001b[0m\u001b[37m\n",
      "\u001b[92mOutput model file: C:/Users/markz/OneDrive/Documents/logs/logs/scalars/C5_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-173816/C5_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-173816_Konverted.py\u001b[0m\u001b[37m\n",
      "\u001b[92mWeights and biases file: C:/Users/markz/OneDrive/Documents/logs/logs/scalars/C5_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-173816/C5_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-173816_Konverted_weights.npz\u001b[0m\u001b[37m\n",
      "\u001b[38;5;220m\n",
      "â— Make sure to change the path inside the wrapper file to your weights if you move the file elsewhere.\u001b[0m\u001b[37m\n",
      "Converted C5_Monahans_T90F_P1000_2000_LHS10000__100_4_20_100_20201222-173816\n"
     ]
    }
   ],
   "source": [
    "for i in dirList:\n",
    "    modelPath = os.path.join(path, i)\n",
    "    tempname= i\n",
    "    '''# Debug\n",
    "    print('modelPath: '+modelPath)\n",
    "    print('tempname: '+tempname)'''\n",
    "    \n",
    "    # Load\n",
    "    loaded_model = tf.keras.models.load_model(modelPath)\n",
    "    \n",
    "    # Re-save as .h5 in modelPath as tempname.h5. Intermediate step\n",
    "    loaded_model.save(modelPath+'\\\\'+tempname+'.h5', save_format='h5')\n",
    "    print('Saved to: '+modelPath+'\\\\'+tempname+'.h5')\n",
    "    \n",
    "    # Convert\n",
    "    konverter.konvert(modelPath+'\\\\'+tempname+'.h5', output_file=modelPath+'\\\\'+tempname+'_Konverted')\n",
    "    # Print\n",
    "    print('Converted '+tempname+'n\\'+'================')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = np.load(r'C:\\Users\\win7\\PycharmProjects\\Ln_phi_model\\Applied_model\\numpy_relu\\lnphi_nC10_T300-600_P5-100__100_4_20_100_20200915-230243\\lnphi_nC10_T300-600_P5-100__100_4_20_100_20200915-230243_Konverted_weights.npz',\n",
    "             allow_pickle=True)\n",
    "w, b = wb['wb']\n",
    "\n",
    "def predict(x,w,b):\n",
    "    #x = np.array(x, dtype=np.float32)\n",
    "    l0 = np.dot(x, w[0]) + b[0]\n",
    "    l0 = np.where(l0 > 0, l0, l0 * 0.1)\n",
    "    l1 = np.dot(l0, w[1]) + b[1]\n",
    "    l1 = np.where(l1 > 0, l1, l1 * 0.1)\n",
    "    l2 = np.dot(l1, w[2]) + b[2]\n",
    "    l2 = np.where(l2 > 0, l2, l2 * 0.1)\n",
    "    l3 = np.dot(l2, w[3]) + b[3]\n",
    "    l3 = np.where(l3 > 0, l3, l3 * 0.1)\n",
    "    l4 = np.dot(l3, w[4]) + b[4]\n",
    "    return l4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify exactly same prediction \n",
    "true_val = 0.72913244\n",
    "X_prepared_nC10 = np.array([0.096363940, 0.231393959, 0.228188976, 0.098272932], dtype=np.float32)\n",
    "y_hat_nC10 = predict(X_prepared_nC10,w,b)\n",
    "y_hat_nC10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit predict(X_prepared_nC10,w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization with numpy\n",
    "Extract the min-max values stored in the pipeline.  \n",
    "    \n",
    "    pr.attr_full_pipeline_nC4.named_transformers_.num.named_steps.min_max_scaler.data_min_\n",
    "    Out[37]: array([0.01831612, 0.006697  , 0.006697  , 0.01831612])\n",
    "    pr.attr_full_pipeline_nC4.named_transformers_.num.named_steps.min_max_scaler.data_max_\n",
    "    Out[38]: array([15.97685643,  0.75642223,  0.29020326,  6.85400705])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test speedup with numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def predict_numba(x):#predict_numba(x,w0,w1,w2,w3,w4,b0,b1,b2,b3,b4)\n",
    "    #x = np.array(x, dtype=np.float32)\n",
    "    l0 = np.dot(x, w0) + b0\n",
    "    l0 = np.where(l0 > 0, l0, l0 * 0.1)\n",
    "    l1 = np.dot(l0, w1) + b1\n",
    "    l1 = np.where(l1 > 0, l1, l1 * 0.1)\n",
    "    l2 = np.dot(l1, w2) + b2\n",
    "    l2 = np.where(l2 > 0, l2, l2 * 0.1)\n",
    "    l3 = np.dot(l2, w3) + b3\n",
    "    l3 = np.where(l3 > 0, l3, l3 * 0.1)\n",
    "    l4 = np.dot(l3, w4) + b4\n",
    "    return l4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = w[0].astype('float64')\n",
    "w1 = w[1].astype('float64')\n",
    "w2 = w[2].astype('float64')\n",
    "w3 = w[3].astype('float64')\n",
    "w4 = w[4].astype('float64')\n",
    "\n",
    "b0 = b[0].astype('float64')\n",
    "b1 = b[1].astype('float64')\n",
    "b2 = b[2].astype('float64')\n",
    "b3 = b[3].astype('float64')\n",
    "b4 = b[4].astype('float64')\n",
    "\n",
    "X_prepared_nC10 = np.array([0.096363940, 0.231393959, 0.228188976, 0.098272932], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit predict_numba(X_prepared_nC10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit predict_numba(X_prepared_nC10,w0,w1,w2,w3,w4,b0,b1,b2,b3,b4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_numba(X_prepared_nC10,w0,w1,w2,w3,w4,b0,b1,b2,b3,b4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l0 = np.dot(X_prepared_nC10, w0) + b0\n",
    "l0 = np.where(l0 > 0, l0, l0 * 0.1)\n",
    "l1 = np.dot(l0, w1) + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l0.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def predict_numba2(x,w0,w1,w2,w3,w4,b0,b1,b2,b3,b4):\n",
    "    #x = np.array(x, dtype=np.float32)\n",
    "    l0 = np.dot(x, w0) + b0\n",
    "    print(l0.dtype)\n",
    "    l0 = np.where(l0 > 0, l0, l0 * 0.1)\n",
    "    print(l0.dtype)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_numba2(X_prepared_nC10,w0,w1,w2,w3,w4,b0,b1,b2,b3,b4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3], dtype=np.float32)\n",
    "y = np.array([-1, -2, -3], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = func(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww = np.concatenate((w[1], w[2]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww[0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
