{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Write numpy LeakyReLu for use in ANN acceleration\n",
    "Tensorflor model.predict is too slow bc it uses tensors optimized for batch predictions\n",
    "\n",
    "How to use:\n",
    "    Set modelPath as the directory containing the saved_model.pb file\n",
    "    Set loaded_model name\n",
    "\n",
    "'''\n",
    "\n",
    "import konverter\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = r'C:\\Users\\win7\\Desktop\\logs\\logs\\scalars\\lnphi_nC4_T300-600_P5-100__100_4_20_100_20200916-112226'\n",
    "tempname='lnphi_nC4_T300-600_P5-100__100_4_20_100_20200916-112226'\n",
    "\n",
    "# Load\n",
    "loaded_model = tf.keras.models.load_model(modelPath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-save as .h5 in current directory\n",
    "\n",
    "loaded_model.save(tempname+'.h5', save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\n",
      "Successfully got model architecture! üòÑ\n",
      "\u001b[0m\u001b[37m\n",
      "\u001b[38;5;220mLayers:\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (4, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;205mactivation: LeakyReLU\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 20)\u001b[0m\u001b[37m\u001b[38;5;119m\n",
      " =======================\n",
      "\u001b[0m\u001b[37m  \u001b[38;5;74mname: dense\u001b[0m\u001b[37m\n",
      "  \u001b[38;5;135mshape: (20, 1)\u001b[0m\u001b[37m\n",
      "\u001b[0m\u001b[37m\u001b[38;5;220m\n",
      "üî® Now building pure Python + NumPy model...\u001b[0m\u001b[37m\n",
      "\u001b[92müôå Saved Konverted model!\u001b[0m\u001b[37m\n",
      "\u001b[92mOutput model file: C:/Users/win7/PycharmProjects/Ln_phi_model/Applied_model/numpy_relu/lnphi_nC4_T300-600_P5-100__100_4_20_100_20200916-112226_Konverted.py\u001b[0m\u001b[37m\n",
      "\u001b[92mWeights and biases file: C:/Users/win7/PycharmProjects/Ln_phi_model/Applied_model/numpy_relu/lnphi_nC4_T300-600_P5-100__100_4_20_100_20200916-112226_Konverted_weights.npz\u001b[0m\u001b[37m\n",
      "\u001b[38;5;220m\n",
      "‚ùó Make sure to change the path inside the wrapper file to your weights if you move the file elsewhere.\u001b[0m\u001b[37m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<konverter.Konverter at 0x1bc413a05c8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert\n",
    "\n",
    "konverter.konvert(tempname+'.h5',\n",
    "                  output_file=os.getcwd()+'\\\\'+tempname+'_Konverted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = np.load(r'C:\\Users\\win7\\PycharmProjects\\Ln_phi_model\\Applied_model\\numpy_relu\\lnphi_nC10_T300-600_P5-100__100_4_20_100_20200915-230243\\lnphi_nC10_T300-600_P5-100__100_4_20_100_20200915-230243_Konverted_weights.npz',\n",
    "             allow_pickle=True)\n",
    "w, b = wb['wb']\n",
    "\n",
    "def predict(x,w,b):\n",
    "    x = np.array(x, dtype=np.float32)\n",
    "    l0 = np.dot(x, w[0]) + b[0]\n",
    "    l0 = np.where(l0 > 0, l0, l0 * 0.1)\n",
    "    l1 = np.dot(l0, w[1]) + b[1]\n",
    "    l1 = np.where(l1 > 0, l1, l1 * 0.1)\n",
    "    l2 = np.dot(l1, w[2]) + b[2]\n",
    "    l2 = np.where(l2 > 0, l2, l2 * 0.1)\n",
    "    l3 = np.dot(l2, w[3]) + b[3]\n",
    "    l3 = np.where(l3 > 0, l3, l3 * 0.1)\n",
    "    l4 = np.dot(l3, w[4]) + b[4]\n",
    "    return l4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75913244], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify exactly same prediction \n",
    "true_val = 0.72913244\n",
    "X_prepared_nC10 = np.array([0.096363940, 0.231393959, 0.228188976, 0.098272932])\n",
    "y_hat_nC10 = predict(X_prepared_nC10)\n",
    "y_hat_nC10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.7 ¬µs ¬± 188 ns per loop (mean ¬± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit predict(X_prepared_nC10,w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization with numpy\n",
    "Extract the min-max values stored in the pipeline.  \n",
    "    \n",
    "    pr.attr_full_pipeline_nC4.named_transformers_.num.named_steps.min_max_scaler.data_min_\n",
    "    Out[37]: array([0.01831612, 0.006697  , 0.006697  , 0.01831612])\n",
    "    pr.attr_full_pipeline_nC4.named_transformers_.num.named_steps.min_max_scaler.data_max_\n",
    "    Out[38]: array([15.97685643,  0.75642223,  0.29020326,  6.85400705])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaenv",
   "language": "python",
   "name": "condaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
