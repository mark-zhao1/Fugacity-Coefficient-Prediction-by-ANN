{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Concatenate all the weights of each component into a np.array. \n",
    "#Then, in prediction, call the same array with the specific component\n",
    "\n",
    "# Now with for loop\n",
    "Want to loop over variable number of components and save weights, biases and transformation constants into a global variables.  \n",
    "\n",
    "Explanation:  \n",
    "Path is the directory containing the logs folders of each component model.  \n",
    "dirList is the list of directories for the component model.  \n",
    "modelPath is the list of paths to the component models.  \n",
    "pipelinePath is the list of paths to the transformation pipeline .pkl files of each model.  \n",
    "wbPath is a custom folder which has the .npk weights and biases of each model. Required, because there is often multiple .npk files within a model's directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\markz\\OneDrive\\Documents\\logs\\logs\\scalars'\n",
    "dirList = [i for i in os.listdir(path) if '_Monahans' in i]\n",
    "modelPath = [os.path.join(path, i) for i in dirList]\n",
    "pipelinePath = [os.path.join(i,j) for i in modelPath for j in os.listdir(i) if '.pkl' in j]\n",
    "wbPath = r'C:\\Users\\markz\\OneDrive\\Documents\\logs\\logs\\scalars\\Monahans_wbfiles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array([])\n",
    "biases = np.array([])\n",
    "for i in os.listdir(wbPath):\n",
    "    temp_w, temp_b = np.load(os.path.join(wbPath, i), allow_pickle=True)['wb']\n",
    "    weights = np.append(weights, temp_w)\n",
    "    biases = np.append(biases, temp_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(weights.shape[0]/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01769394,  0.07590988,  0.0608178 , -0.00701261,  0.02955914,\n",
       "       -0.01444711, -0.00289587,  0.11736303,  0.0118157 ,  0.06475718,\n",
       "        0.00888301,  0.00449676, -0.05129231,  0.01873769,  0.02174392,\n",
       "        0.02099884, -0.05873764, -0.0731374 ,  0.04184343, -0.0197368 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading transformation pipelines\n",
    "We need to extract the values of the min, max from the MinMaxScalers used for attribute and label transformations.  \n",
    "Looks like no alternative than to :  \n",
    "\n",
    "        1) Load the pickled pipelines  \n",
    "        2) Extract min and max values   \n",
    "\n",
    "Load the attribute and label pipelines in pipelinePaths with pickle.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\markz\\OneDrive\\Documents\\logs\\logs\\scalars'\n",
    "dirList = [i for i in os.listdir(path) if '_Monahans' in i]\n",
    "modelPath = [os.path.join(path, i) for i in dirList]\n",
    "pipelinePath = [os.path.join(i,j) for i in modelPath for j in os.listdir(i) if '.pkl' in j]\n",
    "\n",
    "# Load transformation pipelines\n",
    "attr_full_pipelines = []\n",
    "label_full_pipelines = []\n",
    "for i in pipelinePath:\n",
    "    with open(i, 'rb') as f:\n",
    "        temp = pickle.load(f)\n",
    "        attr_full_pipelines.append(temp)\n",
    "        temp = pickle.load(f)   # Loads the next variable (label pipeline)\n",
    "        label_full_pipelines.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33322439 0.08450765 0.07243997 0.35300706]\n",
      "[0.33322439 0.08450765 0.07278082 0.26651361]\n",
      "[0.33322439 0.08450765 0.13153098 0.54917993]\n",
      "[0.33322439 0.08450765 0.24244415 0.96226571]\n",
      "[0.33322439 0.08450765 0.46676402 1.8123919 ]\n",
      "[0.33322439 0.08450765 0.79030306 3.36885095]\n"
     ]
    }
   ],
   "source": [
    "# Extract values\n",
    "for i in attr_full_pipelines:\n",
    "    print(i.named_transformers_.num.named_steps.min_max_scaler.data_min_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.33322439, 0.08450765, 0.07243997, 0.35300706]),\n",
       " array([0.33322439, 0.08450765, 0.07278082, 0.26651361]),\n",
       " array([0.33322439, 0.08450765, 0.13153098, 0.54917993]),\n",
       " array([0.33322439, 0.08450765, 0.24244415, 0.96226571]),\n",
       " array([0.33322439, 0.08450765, 0.46676402, 1.8123919 ]),\n",
       " array([0.33322439, 0.08450765, 0.79030306, 3.36885095])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.named_transformers_.num.named_steps.min_max_scaler.data_min_ for i in attr_full_pipelines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.84655484]),\n",
       " array([-0.19558728]),\n",
       " array([-1.72390144]),\n",
       " array([-4.3244542]),\n",
       " array([-9.90714487]),\n",
       " array([-23.00771095])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The label pipeline was simpler\n",
    "[i[0].data_min_ for i in label_full_pipelines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.84655484])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_full_pipelines[0][0].data_min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class prclass():\n",
    "    def load_pipeline_values(self, pipelinePath):\n",
    "        '''\n",
    "        # Extract min, range values of transformation pipelines.\n",
    "        :param pipelinePath: List of paths to the pipeline .pkl files\n",
    "        :return:\n",
    "        '''\n",
    "        # Load transformation pipelines\n",
    "        self.attr_full_pipelines = []\n",
    "        self.label_full_pipelines = []\n",
    "        for i in pipelinePath:\n",
    "            with open(i, 'rb') as f:\n",
    "                temp = pickle.load(f)\n",
    "                self.attr_full_pipelines.append(temp)\n",
    "                temp = pickle.load(f)   # Loads the next variable (label pipeline)\n",
    "                self.label_full_pipelines.append(temp)\n",
    "\n",
    "        global min_attr\n",
    "        global range_attr\n",
    "        global min_label\n",
    "        global range_label\n",
    "\n",
    "        min_attr = np.array([i.named_transformers_.num.named_steps.min_max_scaler.data_min_\n",
    "                    for i in self.attr_full_pipelines])\n",
    "        range_attr = np.array([i.named_transformers_.num.named_steps.min_max_scaler.data_range_\n",
    "                      for i in self.attr_full_pipelines])\n",
    "        min_label = np.array([i[0].data_min_ for i in self.label_full_pipelines])\n",
    "        range_label = np.array([i[0].data_range_ for i in self.label_full_pipelines])\n",
    "\n",
    "        print('Transformation pipeline values extracted.')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation pipeline values extracted.\n"
     ]
    }
   ],
   "source": [
    "pr = prclass()\n",
    "pr.load_pipeline_values(pipelinePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33322439, 0.08450765, 0.07243997, 0.35300706],\n",
       "       [0.33322439, 0.08450765, 0.07278082, 0.26651361],\n",
       "       [0.33322439, 0.08450765, 0.13153098, 0.54917993],\n",
       "       [0.33322439, 0.08450765, 0.24244415, 0.96226571],\n",
       "       [0.33322439, 0.08450765, 0.46676402, 1.8123919 ],\n",
       "       [0.33322439, 0.08450765, 0.79030306, 3.36885095]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[57.73394588,  1.34333762,  0.07243997,  5.87113269],\n",
       "       [57.73394588,  1.34333762,  0.07278082,  4.62876427],\n",
       "       [57.73394588,  1.34333762,  0.13153098,  9.53806626],\n",
       "       [57.73394588,  1.34333762,  0.24244415, 16.71247182],\n",
       "       [57.73394588,  1.34333762,  0.46676402, 31.48419176],\n",
       "       [57.73394588,  1.34333762,  0.79030306, 58.52241431]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -0.84655484],\n",
       "       [ -0.19558728],\n",
       "       [ -1.72390144],\n",
       "       [ -4.3244542 ],\n",
       "       [ -9.90714487],\n",
       "       [-23.00771095]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.22907247],\n",
       "       [ 1.69931711],\n",
       "       [ 1.05474704],\n",
       "       [ 2.8833128 ],\n",
       "       [ 6.86984865],\n",
       "       [16.88401123]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict $ln\\phi$ for all components at once\n",
    "This should be faster than to sequentially predict.  \n",
    "Verified working.  \n",
    "Loops over number of components and predicts sequentially.  \n",
    "Each component has 5 layers in w and b. Therefore, we iterate the variable i and use j = 5*i as a method to iterate through the dimensions of the w and b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([4.351332773, 0.351614082, 0.65064075, 7.759843106\n",
    "], dtype=np.float32)\n",
    "y_C0 = -9.81576967\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = weights\n",
    "b = biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    x = np.array(x, dtype=np.float32)\n",
    "    y_hat = np.empty(6)\n",
    "    for i in range(0,6):\n",
    "        j = 5*i\n",
    "        xx = (x - min_attr[i]) / range_attr[i]\n",
    "        l0 = np.dot(xx, w[j]) + b[j]\n",
    "        l0 = np.where(l0 > 0, l0, l0 * 0.1)\n",
    "        l1 = np.dot(l0, w[j+1]) + b[j+1]\n",
    "        l1 = np.where(l1 > 0, l1, l1 * 0.1)\n",
    "        l2 = np.dot(l1, w[j+2]) + b[j+2]\n",
    "        l2 = np.where(l2 > 0, l2, l2 * 0.1)\n",
    "        l3 = np.dot(l2, w[j+3]) + b[j+3]\n",
    "        l3 = np.where(l3 > 0, l3, l3 * 0.1)\n",
    "        l4 = np.dot(l3, w[j+4]) + b[j+4]\n",
    "        y_hat[i] = range_label[i] * l4 + min_label[i]\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-19.2063897 ,   4.29300283, -10.49241499, -19.14172246,\n",
       "        -8.17128357, -22.72059725])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-19.2063897 ,   4.29300283, -10.49241499, -19.14172246,\n",
       "        -8.17128357, -22.72059725])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#C5\n",
    "x = np.array([17.75106602, 0.751298761, 1.221377452, 30.69729556\n",
    "], dtype=np.float32)\n",
    "y_true = -22.76842177\n",
    "predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct X_unprepared efficiently\n",
    "X_unprepared is the input vector to the ANN. It must be efficiently made. Construction time is not always counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unp = np.empty((6,4))\n",
    "a_mix = 1\n",
    "b_mix = 2\n",
    "b_i = np.ones(6)*3\n",
    "b_i = b_i.T\n",
    "sumx = np.ones(6)*4\n",
    "sumx = sumx.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  2.        ,  0.07243997,  5.87113269],\n",
       "       [ 1.        ,  2.        ,  0.07278082,  4.62876427],\n",
       "       [ 1.        ,  2.        ,  0.13153098,  9.53806626],\n",
       "       [ 1.        ,  2.        ,  0.24244415, 16.71247182],\n",
       "       [ 1.        ,  2.        ,  0.46676402, 31.48419176],\n",
       "       [ 1.        ,  2.        ,  0.79030306, 58.52241431]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_unp[:,:2] = a_mix, b_mix\n",
    "X_unp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 3., 3., 3., 3., 3.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3., 4.],\n",
       "       [1., 2., 3., 4.],\n",
       "       [1., 2., 3., 4.],\n",
       "       [1., 2., 3., 4.],\n",
       "       [1., 2., 3., 4.],\n",
       "       [1., 2., 3., 4.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_unp[:, 2:] = np.column_stack((b_i, sumx))\n",
    "X_unp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now try with numba jit\n",
    "Figure out variable types for Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all variables np.float32\n",
    "min_attr = min_attr.astype(np.float32)\n",
    "range_attr = range_attr.astype(np.float32)\n",
    "range_label = range_label.astype(np.float32)\n",
    "min_label = min_label.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the type of xx, see if infering type is possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True, locals={'l0':numba.float32})\n",
    "def predict2(X_unp):\n",
    "    x = X_unp.astype(np.float32)\n",
    "    y_hat = np.empty(6,dtype=np.float32)\n",
    "    for i in range(0,1):\n",
    "        j = 5*i\n",
    "        xx = (x[i] - min_attr[i]) / range_attr[i]\n",
    "        l0 = np.dot(xx, w[j]) + b[j]\n",
    "        l00 = np.where(l0 > 0, l0, l0 * 0.1)    \n",
    "        l1 = np.dot(l0, w[j+1]) + b[j+1]\n",
    "        l1 = np.where(l1 > 0, l1, l1 * 0.1)\n",
    "        l2 = np.dot(l1, w[j+2]) + b[j+2]\n",
    "        l2 = np.where(l2 > 0, l2, l2 * 0.1)\n",
    "        l3 = np.dot(l2, w[j+3]) + b[j+3]\n",
    "        l3 = np.where(l3 > 0, l3, l3 * 0.1)\n",
    "        l4 = np.dot(l3, w[j+4]) + b[j+4]\n",
    "        y_hat[i] = range_label[i] * l4 + min_label[i]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1mType of variable 'l1' cannot be determined, operation: $156binary_add.51, location: <ipython-input-197-43e3d0427e39> (10)\n\u001b[1m\nFile \"<ipython-input-197-43e3d0427e39>\", line 10:\u001b[0m\n\u001b[1mdef predict2(X_unp):\n    <source elided>\n        l00 = np.where(l0 > 0, l0, l0 * 0.1)    \n\u001b[1m        l1 = np.dot(l0, w[j+1]) + b[j+1]\n\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-198-a910eb6a9782>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredict2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_unp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\gputest\\lib\\site-packages\\numba\\core\\dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[1;34m(self, *args, **kws)\u001b[0m\n\u001b[0;32m    413\u001b[0m                 \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m             \u001b[0merror_rewrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'typing'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnsupportedError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m             \u001b[1;31m# Something unsupported is present in the user code, add help info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gputest\\lib\\site-packages\\numba\\core\\dispatcher.py\u001b[0m in \u001b[0;36merror_rewrite\u001b[1;34m(e, issue_type)\u001b[0m\n\u001b[0;32m    356\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m                 \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m         \u001b[0margtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gputest\\lib\\site-packages\\numba\\core\\utils.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1mType of variable 'l1' cannot be determined, operation: $156binary_add.51, location: <ipython-input-197-43e3d0427e39> (10)\n\u001b[1m\nFile \"<ipython-input-197-43e3d0427e39>\", line 10:\u001b[0m\n\u001b[1mdef predict2(X_unp):\n    <source elided>\n        l00 = np.where(l0 > 0, l0, l0 * 0.1)    \n\u001b[1m        l1 = np.dot(l0, w[j+1]) + b[j+1]\n\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n\u001b[0m"
     ]
    }
   ],
   "source": [
    "predict2(X_unp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def jit_sample_1(x,y):\n",
    "    tmp = np.dot(x[0],y) + 4;\n",
    "    return tmp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.ones((3,3), dtype=np.float32)\n",
    "y = np.ones((3), dtype=np.float32)*2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.dot(x,y) in numba requires x,y to have the same data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jit_sample_1(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.100000381469727"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test phase stability\n",
    "Test the ANN for 2-phase stability.  \n",
    "Run with the Monahans oil in Numba_no_class_Monahans.py.  \n",
    "Disable any profiling code for the run.\n",
    "From Fig. 6.23 of Okuno dissertation, the following conditions should be in 2-phase:  \n",
    "\n",
    "         INPUTS\n",
    "    P = 1500 # psia\n",
    "    T = 549.67  # R, 90 F\n",
    "    gas_r = 0.6\n",
    "\n",
    "    # Monahans Clearfork Oil, Table 6.3 of Okuno\n",
    "    z = np.array([0.0001, 0.3056, 0.2027, 0.1589, 0.2327, 0.1000])\n",
    "    z_gas = np.array([0.95, 0.05, 0.0000, 0.0000, 0.0000, 0.0000])\n",
    "    z = gas_r*z_gas + (1-gas_r)*z\n",
    "    w = np.array([0.225, 0.008, 0.127, 0.240, 0.609, 1.042])\n",
    "    Pc = np.array([1069.87, 667.20, 658.59, 487.51, 329.42, 258.78])  # [psia]\n",
    "    Tc = np.array([547.56, 343.08, 612.02, 835.06, 1086.35, 1444.93])  # [R]\n",
    "    BIP = np.array([[0.000, 0.094, 0.094, 0.094, 0.095, 0.095],\n",
    "                    [0.094, 0.000, 0.000, 0.000, 0.000, 0.000],\n",
    "                    [0.094, 0.000, 0.000, 0.000, 0.000, 0.000],\n",
    "                    [0.094, 0.000, 0.000, 0.000, 0.000, 0.000],\n",
    "                    [0.095, 0.000, 0.000, 0.000, 0.000, 0.000],\n",
    "                    [0.095, 0.000, 0.000, 0.000, 0.000, 0.000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results from conventional SS from Numba_no_class_Monahans.py, useModel = False  \n",
    "\n",
    "118 SS iterations  \n",
    "\n",
    "        END 2-phase flash\n",
    "        liq and vap comp:\n",
    "        [0.52769919 0.12540564 0.08586372 0.07763951 0.12718364 0.05620829]\n",
    "        [6.74381163e-01 2.18368365e-01 6.92913879e-02 2.88636319e-02\n",
    "         9.03781105e-03 5.76413831e-05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try with the ANNs.  \n",
    "\n",
    "Settings:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
